#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jun  8 13:29:31 2017

@author: jhartmann
"""


import sys
import pymysql
import getpass
import datetime
from bs4 import BeautifulSoup

try:
    import urllib.request as urllib2
except ImportError:
    import urllib2
    
pw = ''

dbuser = ''
db = ''
dbhost = ''

dbconn = pymysql.connect(host= dbhost,
                         user= dbuser,
                         passwd= pw,
                         db= db,
                         use_unicode=True,
                         charset="utf8mb4")
cursor = dbconn.cursor()

selectCommitters = 'SELECT svn_id \
                    FROM apache_committers \
                    WHERE project_name = %s AND real_name = %s  \
                    '                


insertCommitters = 'INSERT INTO apache_committers (datasource_id, \
                                                svn_id, \
                                                real_name, \
                                                project_name, \
                                                role_on_project, \
                                                last_updated,\
                                                organization_name) \
                                                VALUES  (%s, %s, %s, %s,%s, %s, %s)'
                    
#Airies Project Information
teamUrl = 'http://aries.apache.org/community/people.html'
project_name = 'aries'
role = 'Committer'
data_id = 70914

i = 0 
hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',
       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
       'Accept-Encoding': 'none',
       'Accept-Language': 'en-US,en;q=0.8',
       'Connection': 'keep-alive'}
 
try:
    while True:
        #grap the team page
        req = urllib2.Request(teamUrl,headers=hdr)
        teamHtml = urllib2.urlopen(req).read()
      
        soup = BeautifulSoup(teamHtml, 'html.parser')
        div = soup.find_all('table')
        table = div[3].find_all(['table'])

        
        #parser to get names and organizations
        row = table[0].find_all(['tr'])[i + 1]
        cell = row.find_all(['td'])
        real_name = cell[0].contents[0]
        organization = cell[1].contents[0]
        print(real_name, organization)
        time = datetime.datetime.now()
        
        try:
            cursor.execute(selectCommitters, (project_name, real_name))
            committerList = cursor.fetchall()
            screen_name = committerList[0][0]
            print(screen_name) 
        except:
            screen_name = ''
        
        i = i + 1
        
      
        try:     
            cursor.execute(insertCommitters, (data_id, screen_name, real_name, project_name, role, time, organization))
            dbconn.commit()
        
        except pymysql.Error as error:
               print(error)
               dbconn.rollback()        
except:
    pass

dbconn.close
